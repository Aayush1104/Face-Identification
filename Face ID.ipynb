{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f03231d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.12.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\aayush\\anaconda3\\lib\\site-packages (4.8.0.74)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\aayush\\anaconda3\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.7.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.13)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (16.0.6)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.6.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.56.2)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.38.4)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.10.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.29.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\aayush\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.12.0 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "415b1de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "# Define directories\n",
    "POS_PATH = os.path.join('data', 'positive')\n",
    "NEG_PATH = os.path.join('data', 'negative')\n",
    "ANC_PATH = os.path.join('data', 'anchor')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(POS_PATH, exist_ok=True)\n",
    "os.makedirs(NEG_PATH, exist_ok=True)\n",
    "os.makedirs(ANC_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6189127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c4274ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame = frame[35:35+250, 200:200+250, :]\n",
    "    cv2.imshow('Image Collection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'):\n",
    "        imgname = os.path.join(ANC_PATH, f'{uuid.uuid1()}.jpg')\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('p'):\n",
    "        imgname = os.path.join(POS_PATH, f'{uuid.uuid1()}.jpg')\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c364dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_data = tf.data.Dataset.list_files(os.path.join(ANC_PATH, '*.jpg')).take(300)\n",
    "positive_data = tf.data.Dataset.list_files(os.path.join(POS_PATH, '*.jpg')).take(300)\n",
    "negative_data = tf.data.Dataset.list_files(os.path.join(NEG_PATH, '*.jpg')).take(300)\n",
    "\n",
    "def preprocess_tf(file_path):\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (105, 105))\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "positives = tf.data.Dataset.zip((anchor_data, positive_data, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor_data)))))\n",
    "negatives = tf.data.Dataset.zip((anchor_data, negative_data, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor_data)))))\n",
    "data_tf = positives.concatenate(negatives)\n",
    "data_tf = data_tf.shuffle(buffer_size=1024)\n",
    "\n",
    "data_count = len(positives) + len(negatives)\n",
    "train_size = int(0.7 * data_count)\n",
    "\n",
    "train_data = data_tf.take(train_size)\n",
    "test_data = data_tf.skip(train_size)\n",
    "\n",
    "# Apply preprocessing and other transformations\n",
    "train_data = train_data.map(lambda anchor, img, label: (preprocess_tf(anchor), preprocess_tf(img), label))\n",
    "test_data = test_data.map(lambda anchor, img, label: (preprocess_tf(anchor), preprocess_tf(img), label))\n",
    "\n",
    "train_data = train_data.cache()\n",
    "train_data = train_data.shuffle(buffer_size=1024)\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)\n",
    "\n",
    "test_data = test_data.cache()\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18057bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_layer():\n",
    "    inp = Input(shape=(105, 105, 3), name='input_img')\n",
    "    c1 = Conv2D(64, (10, 10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(2, padding='same')(c1)\n",
    "    c2 = Conv2D(128, (7, 7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(2, padding='same')(c2)\n",
    "    c3 = Conv2D(128, (4, 4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(2, padding='same')(c3)\n",
    "    c4 = Conv2D(256, (4, 4), activation='relu')(m3)\n",
    "    flat = Flatten()(c4)\n",
    "    den = Dense(4096, activation='sigmoid')(flat)\n",
    "    return Model(inputs=inp, outputs=den, name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e17695e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Distance(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)\n",
    "\n",
    "l1 = L1Distance()\n",
    "\n",
    "def make_siamese_model(embedding_model):\n",
    "    input_img = Input(name='input_img', shape=(105, 105, 3))\n",
    "    validation_img = Input(name='validation_img', shape=(105, 105, 3))\n",
    "    distances = l1(embedding_model(input_img), embedding_model(validation_img))\n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    return Model(inputs=[input_img, validation_img], outputs=classifier, name='SiameseNeuralNetwork')\n",
    "\n",
    "# Create the embedding model\n",
    "embedding = build_embedding_layer()\n",
    "\n",
    "# Create the siamese model using the embedding model\n",
    "siamese_model = make_siamese_model(embedding)\n",
    "\n",
    "# Training setup\n",
    "binary_loss = BinaryCrossentropy()\n",
    "opt = Adam(1e-4)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f03c429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 88s 4s/step - Loss: 0.5305\n",
      "\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 85s 4s/step - Loss: 0.2560\n",
      "\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 83s 4s/step - Loss: 0.1875\n",
      "\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 89s 4s/step - Loss: 0.1168\n",
      "\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 91s 4s/step - Loss: 0.0565\n",
      "\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 83s 4s/step - Loss: 0.0515\n",
      "\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 85s 4s/step - Loss: 0.0266\n",
      "\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 82s 4s/step - Loss: 0.0129\n",
      "\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 82s 4s/step - Loss: 0.0132\n",
      "\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 83s 4s/step - Loss: 0.0154\n",
      "\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 80s 4s/step - Loss: 0.0246\n",
      "\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 83s 4s/step - Loss: 0.0127\n",
      "\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 83s 4s/step - Loss: 0.0322\n",
      "\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 79s 4s/step - Loss: 0.0402\n",
      "\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 81s 4s/step - Loss: 0.0190\n",
      "\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 85s 4s/step - Loss: 0.0122\n",
      "\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 83s 4s/step - Loss: 0.0066\n",
      "\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 86s 4s/step - Loss: 0.0035\n",
      "\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 93s 4s/step - Loss: 0.0024\n",
      "\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 80s 4s/step - Loss: 0.0018\n",
      "\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 80s 4s/step - Loss: 0.0015\n",
      "\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 84s 4s/step - Loss: 0.0012\n",
      "\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 79s 4s/step - Loss: 0.0011\n",
      "\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 78s 4s/step - Loss: 8.9895e-04\n",
      "\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 81s 4s/step - Loss: 7.7236e-04\n",
      "\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 85s 4s/step - Loss: 6.6747e-04\n",
      "\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 81s 4s/step - Loss: 6.2152e-04\n",
      "\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 79s 4s/step - Loss: 5.2820e-04\n",
      "\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 80s 4s/step - Loss: 4.4453e-04\n",
      "\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 79s 4s/step - Loss: 4.0100e-04\n",
      "\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 78s 4s/step - Loss: 3.5949e-04\n",
      "\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 81s 4s/step - Loss: 3.3181e-04\n",
      "\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 81s 4s/step - Loss: 3.0081e-04\n",
      "\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 86s 4s/step - Loss: 2.6971e-04\n",
      "\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 84s 4s/step - Loss: 2.5413e-04\n",
      "\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 86s 4s/step - Loss: 2.2816e-04\n",
      "\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 80s 4s/step - Loss: 2.1067e-04\n",
      "\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 80s 4s/step - Loss: 1.9293e-04\n",
      "\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 82s 4s/step - Loss: 1.7747e-04\n",
      "\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 81s 4s/step - Loss: 1.6381e-04\n",
      "\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 77s 4s/step - Loss: 1.5237e-04\n",
      "\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 83s 4s/step - Loss: 1.4462e-04\n",
      "\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 88s 4s/step - Loss: 1.3710e-04\n",
      "\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 80s 4s/step - Loss: 1.3164e-04\n",
      "\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 80s 4s/step - Loss: 1.9025e-04\n",
      "\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 87s 4s/step - Loss: 1.4048e-04\n",
      "\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 83s 4s/step - Loss: 0.3699\n",
      "\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 84s 4s/step - Loss: 0.4297\n",
      "\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 86s 4s/step - Loss: 0.2896\n",
      "\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 85s 4s/step - Loss: 0.2025\n",
      "\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 79s 4s/step - Loss: 0.1519\n",
      "\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 82s 4s/step - Loss: 0.1286\n",
      "\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 81s 4s/step - Loss: 0.1134\n",
      "\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 87s 4s/step - Loss: 0.0784\n",
      "\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 83s 4s/step - Loss: 0.0640\n",
      "\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 82s 4s/step - Loss: 0.0514\n",
      "\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 81s 4s/step - Loss: 0.0355\n",
      "\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 81s 4s/step - Loss: 0.0368\n",
      "\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 81s 4s/step - Loss: 0.0375\n",
      "\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 86s 4s/step - Loss: 0.0298\n",
      "\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 86s 4s/step - Loss: 0.0238\n",
      "\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 88s 4s/step - Loss: 0.0204\n",
      "\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 84s 4s/step - Loss: 0.0202\n",
      "\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 84s 4s/step - Loss: 0.0173\n",
      "\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 85s 4s/step - Loss: 0.0161\n",
      "\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 88s 4s/step - Loss: 0.0164\n",
      "\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 88s 4s/step - Loss: 0.0145\n",
      "\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 88s 4s/step - Loss: 0.0137\n",
      "\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 94s 4s/step - Loss: 0.0126\n",
      "\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 89s 4s/step - Loss: 0.0122\n",
      "\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 91s 4s/step - Loss: 0.0117\n",
      "\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 89s 4s/step - Loss: 0.0113\n",
      "\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 85s 4s/step - Loss: 0.0105\n",
      "\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 88s 4s/step - Loss: 0.0104\n",
      "\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 96s 4s/step - Loss: 0.0098\n",
      "\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 94s 4s/step - Loss: 0.0099\n",
      "\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 93s 4s/step - Loss: 0.0089\n",
      "\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 91s 4s/step - Loss: 0.0088\n",
      "\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 88s 4s/step - Loss: 0.0088\n",
      "\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 58s 3s/step - Loss: 0.0090\n",
      "\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 61s 3s/step - Loss: 0.0089\n",
      "\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 65s 3s/step - Loss: 0.0082\n",
      "\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 65s 3s/step - Loss: 0.0076\n",
      "\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 63s 3s/step - Loss: 0.0071\n",
      "\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 64s 3s/step - Loss: 0.0068\n",
      "\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 62s 3s/step - Loss: 0.0068\n",
      "\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 64s 3s/step - Loss: 0.0061\n",
      "\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 62s 3s/step - Loss: 0.0059\n",
      "\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 61s 3s/step - Loss: 0.0058\n",
      "\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 60s 3s/step - Loss: 0.0057\n",
      "\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 63s 3s/step - Loss: 0.0056\n",
      "\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 68s 3s/step - Loss: 0.0057\n",
      "\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 70s 3s/step - Loss: 0.0055\n",
      "\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 62s 3s/step - Loss: 0.0054\n",
      "\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 59s 3s/step - Loss: 0.0053\n",
      "\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 56s 3s/step - Loss: 0.0055\n",
      "\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 56s 3s/step - Loss: 0.0056\n",
      "\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 56s 3s/step - Loss: 0.0076\n",
      "\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 57s 3s/step - Loss: 0.0055\n",
      "\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 56s 3s/step - Loss: 0.0057\n"
     ]
    }
   ],
   "source": [
    "def train_step(batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x = batch[:2]\n",
    "        y = batch[2]\n",
    "        yvector = siamese_model(x, training=True)\n",
    "        loss = binary_loss(y, yvector)\n",
    "\n",
    "    gradient = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    opt.apply_gradients(zip(gradient, siamese_model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "def train_loop(data, epochs):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print('\\nEpoch {}/{}'.format(epoch, epochs))\n",
    "        progressbar = tf.keras.utils.Progbar(len(data))\n",
    "\n",
    "        for idx, batch in enumerate(data):\n",
    "            loss = train_step(batch)\n",
    "            progressbar.update(idx + 1, [('Loss', loss.numpy())])\n",
    "        if epoch % 10 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "EPOCHS = 100\n",
    "train_loop(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85505966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "siamese_model.save('siamesefaceidmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10b4d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b96992e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = next(iter(test_data))\n",
    "test_input, test_val, y_true = test_batch\n",
    "test_input = test_input.numpy()\n",
    "test_val = test_val.numpy()\n",
    "y_true = y_true.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9664f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 397ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.8772344e-05],\n",
       "       [9.9791312e-01],\n",
       "       [9.9996877e-01],\n",
       "       [9.9999803e-01],\n",
       "       [2.7994947e-05],\n",
       "       [2.0443402e-04],\n",
       "       [2.1766123e-04],\n",
       "       [9.9634504e-01],\n",
       "       [4.2643605e-04],\n",
       "       [9.8830295e-01],\n",
       "       [9.9976277e-01],\n",
       "       [9.9967408e-01],\n",
       "       [9.8407143e-01],\n",
       "       [9.9985605e-01],\n",
       "       [1.6597282e-06],\n",
       "       [3.2699118e-05]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = siamese_model.predict([test_input, test_val])\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c12e1060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = np.array(predict)\n",
    "predictions_binary = (predict > 0.5).astype(int)\n",
    "predictions_list = predictions_binary.flatten().tolist()\n",
    "predictions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ef89e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea6ac39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Precision()\n",
    "m.update_state(y_true, predictions_list)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d992a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Recall()\n",
    "m.update_state(y_true, predictions_list)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b98be1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "249586ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('siamesefaceidmodel.h5', custom_objects={'L1Distance': L1Distance, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "581a2ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 398ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9966782e-01],\n",
       "       [9.9965864e-01],\n",
       "       [2.7980012e-01],\n",
       "       [9.9999803e-01],\n",
       "       [9.9921364e-01],\n",
       "       [9.3288195e-01],\n",
       "       [1.0000000e+00],\n",
       "       [9.9997789e-01],\n",
       "       [9.9994057e-01],\n",
       "       [9.3153822e-01],\n",
       "       [9.9973702e-01],\n",
       "       [5.3218720e-08],\n",
       "       [9.1975421e-01],\n",
       "       [9.9999815e-01],\n",
       "       [9.9999142e-01],\n",
       "       [9.1079937e-06]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([test_input, test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30242e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model, detection_threshold, verification_threshold):\n",
    "    resultingdata = []\n",
    "    for image in os.listdir(os.path.join('InfoStack', 'VerifiedImgs')):\n",
    "        input_img = preprocess_tf(os.path.join('InfoStack', 'InputImgs', 'InputImgs.jpg'))\n",
    "        valid_img = preprocess_tf(os.path.join('InfoStack', 'VerifiedImgs', image))\n",
    "    \n",
    "        results = model.predict(list(np.expand_dims([input_img, valid_img], axis=1)))\n",
    "        resultingdata.append(results)\n",
    "    \n",
    "    detection = np.sum(np.array(resultingdata) > detection_threshold)\n",
    "    verification = detection / len(os.listdir(os.path.join('InfoStack', 'VerifiedImgs')))\n",
    "    verified = False\n",
    "    if verification > verification_threshold:\n",
    "        verified = True\n",
    "    else:\n",
    "        verified = False\n",
    "    \n",
    "    return resultingdata, verified\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a4da663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame = frame[60:60+250, 250:250+250, :]\n",
    "    cv2.imshow('Verification', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
    "        imgname = os.path.join('InfoStack', 'InputImgs', 'InputImgs.jpg')\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        resultingdata, verified = verify(model, 0.5, 0.5)\n",
    "        print(verified)\n",
    "        \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7cd99aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[0.99999964]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[0.99999994]], dtype=float32),\n",
       " array([[0.9999999]], dtype=float32),\n",
       " array([[0.94146734]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[0.9999997]], dtype=float32),\n",
       " array([[0.9999998]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[0.99999994]], dtype=float32),\n",
       " array([[0.99999994]], dtype=float32),\n",
       " array([[0.99999994]], dtype=float32),\n",
       " array([[0.99999994]], dtype=float32),\n",
       " array([[0.99999875]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[0.9999999]], dtype=float32),\n",
       " array([[0.9999935]], dtype=float32),\n",
       " array([[1.]], dtype=float32),\n",
       " array([[0.9999865]], dtype=float32),\n",
       " array([[0.99999964]], dtype=float32),\n",
       " array([[0.9999761]], dtype=float32),\n",
       " array([[0.99996716]], dtype=float32),\n",
       " array([[0.99995446]], dtype=float32),\n",
       " array([[0.9996641]], dtype=float32),\n",
       " array([[0.99958134]], dtype=float32),\n",
       " array([[0.99963444]], dtype=float32),\n",
       " array([[0.9999875]], dtype=float32),\n",
       " array([[0.99925137]], dtype=float32),\n",
       " array([[0.999989]], dtype=float32),\n",
       " array([[0.9999948]], dtype=float32),\n",
       " array([[0.9999946]], dtype=float32),\n",
       " array([[0.9999876]], dtype=float32),\n",
       " array([[0.99999213]], dtype=float32),\n",
       " array([[0.9999994]], dtype=float32)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultingdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7c5b5cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.squeeze(resultingdata) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39f44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
